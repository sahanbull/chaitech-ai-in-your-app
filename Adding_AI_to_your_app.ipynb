{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c5e00a",
   "metadata": {},
   "source": [
    "# Adding AI to Your App\n",
    "\n",
    "There are multiple approaches one can use to leverage AI and ML in their business idea. \n",
    "1. Building your own proprietary model\n",
    "2. Using a pre-trained model within your application\n",
    "3. Leverage Cloud providers to support AI functions in your application\n",
    "\n",
    "These different approaches have pros and cons. Approach 1 gives most degree of control to you as a business in terms of ***taking ownership*** and ***being independent***. \n",
    "\n",
    "This notebook provides code examples in going about building your proprietary ML model in part 1. Then in part 2, we look at an example of how a model can be evaluated. This function is quite important as model evaluation is critical for a business regardless the model is built in-house or provided by a an external vendor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e45c1",
   "metadata": {},
   "source": [
    "# Part 1: Building your Proprietary AI model\n",
    "\n",
    "In this section, we look at how a ML model can be by built from scratch for your organisation. As seen from the example, this appears to be the more complex approach to leveraging ML as it entails costs relating to sourcing the relevant data and expertise required to building and maintaining your in-house model. In a strategic perspective, this approach is more preferable as it adds true value to the business as the ML model becomes the intellectual property of your business and gives the competitive edge. It also frees your business from having to rely on 3rd party licensing restrictions and terms of service agreements that are governed by the true owners of the AI/ML models that may become critical to your business.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05307fb2",
   "metadata": {},
   "source": [
    "## Installing the Python Libraries\n",
    "\n",
    "The first step is to install the python libraries that are needed for training our own ML model. There are many off-the-shelf machine learning libraries that are available in majority of programming languages to use well tested ML algorithms to train models with your own data. These libraries often come with favorable licenses (Eg. Apache 2, MIT and BSD to name a few) that will give your the freedom to use these tools without compromising the legal ownership of the models you train with them. \n",
    "\n",
    "In this example, we use Python, a programming language that has a very rich ecosystem for data science and machine learning. For the specific implementation, we need [scikit-learn](https://scikit-learn.org/stable/) and [pandas](https://pandas.pydata.org/). We can use [pip](https://pypi.org/project/pip/) Python package manager to install these two libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca5757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf434e",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We use a popular publicly available labelled [sentiment analysis dataset](https://www.cs.cornell.edu/people/pabo/movie-review-data/) to demonstrate the different approaches. We use a star rating dataset from the famous movie review website, [IMDB](https://www.imdb.com/).\n",
    "\n",
    "First, we load the data from the local disc using the `load_data` function that has been implemented here. Then we convert that dataset into a `pandas.DataFrame` object that is highly compatible with `scikit-learn` machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required functions\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "\n",
    "data_dir = \"data\"\n",
    "pos_data_dir = join(data_dir, \"pos\")\n",
    "neg_data_dir = join(data_dir, \"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4335d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, label):\n",
    "    files = [join(filepath, filename) for filename in listdir(filepath) if filename.endswith(\".txt\")]\n",
    "    records = []\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        records.append({\"text\": text, \"label\": label})\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "pos = load_data(pos_data_dir, 1)\n",
    "neg = load_data(neg_data_dir, 0)\n",
    "\n",
    "records_df = shuffle(pd.DataFrame(pos + neg)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752e128",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "When training a machine learning model, we need to make sure that there is an ***unseen*** set of examples that we can use to evaluate the true performance of the trained machine learning model. A popular approach to pre-allocate a percentage of the full dataset for testing the trained model and avoid using that data during the model training process.  \n",
    "\n",
    "`scikit-learn` already provides functions that can easily create this test-data allocation for us. In the following step, we create the train-test data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = records_df[\"text\"]\n",
    "y = records_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade3c62",
   "metadata": {},
   "source": [
    "### Data Vectorisation\n",
    "\n",
    "Machine Learning models dominantly work with ***numerical representations***. What that means is that the input we provide into the machine learning algorithm should contain numbers rather than letters and symbols. In this example, we are working with movie reviews that are text representations. The process of taking non-numerical data and transforming them into a numerical vectors in a sensible manner is called ***data vectorisation*** in data science. \n",
    "\n",
    "In order to create numerical representations of the text we have, there are well tested methods such as extracting the [TFIDF representation](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) of the textual document. We use pre-built functions available in `scikit-learn` in order to vectorise text. `scikit-learn` library provides different vectorisation methods (a.k.a feature extraction) for different modalities such as [text](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) and [images](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.image).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260845a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectoriser = TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectoriser.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439e6c9",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "After vectorising the data, we choose an appropriate machine learning model and train it by ***fitting the model*** to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa89f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "print(list(y_train_pred))\n",
    "print(list(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67e18d",
   "metadata": {},
   "source": [
    "### Model Testing\n",
    "\n",
    "Once the model is trained, we need to see how robust this model is in making predictions on data that it hasn't seen before. We can use the pre-allocated test data to serve this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectoriser.transform(X_test)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe85fd7",
   "metadata": {},
   "source": [
    "## Example Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = list(X_test)[1]\n",
    "example_label = list(y_test)[1]\n",
    "\n",
    "print(\"Text: {}\\n Actual Label: {}\".format(example_text, example_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ad905",
   "metadata": {},
   "source": [
    "### Predicting on example with our proprietary  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vect = vectoriser.transform([example_text])\n",
    "y_pred = model.predict(x_vect)\n",
    "print(\"Predicted Label: {}\".format(y_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ed81b",
   "metadata": {},
   "source": [
    "# Part 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349ec6d",
   "metadata": {},
   "source": [
    "## Evaluating Accuracy of the train and Test data\n",
    "\n",
    "Evaluating a trained machine learning model is critical to establishing the value it can bring to your business. In this section we look at how we can evaluate the performance of the trained sentiment classification model. \n",
    "\n",
    "The [accuracy score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) can be used here to evaluate classification accuracy. \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Using the `accuracy_score` function in `sklearn.metrics` module, calculate the accuracy classification accuracy of the trained model based on both training data and testing data (using actual and predicted labels)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = # insert code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e22614",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = # insert code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model on training data: {}\".format(train_accuracy))\n",
    "print(\"Accuracy of the model on test data: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
